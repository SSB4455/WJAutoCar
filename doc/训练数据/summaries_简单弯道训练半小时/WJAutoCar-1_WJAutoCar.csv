Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,1.4189383,0.00029700002,-0.02120708,-0.5585959707637888,638.8,-0.5585959722908834
20000,1.4171461,0.00029098688,-0.06338573,1.361024774795611,370.4074074074074,1.3610247834068205
30000,1.4156107,0.00028498683,-0.01681134,1.461779023842867,183.0566037735849,1.4617790368227463
40000,1.4146733,0.00027899627,0.071591355,1.4941993649178693,126.69620253164557,1.4916338298278742
50000,1.4125472,0.00027300304,0.19986796,1.6189196736976876,110.88636363636364,1.619766772128223
60000,1.411194,0.00026699385,0.32056895,1.4313936405563683,90.75,1.4313936501189515
70000,1.4093204,0.0002610052,0.38805175,1.5131227405123766,79.09677419354838,1.5085111144112378
80000,1.4071571,0.0002550113,0.4450206,1.534879152544443,74.74809160305344,1.5415489978462684
90000,1.4056971,0.00024901025,0.5290039,2.0021123828196847,80.20661157024793,1.9955918490886688
100000,1.4043567,0.00024301335,0.5913747,2.3164252772023346,87.3125,2.316425285834287
